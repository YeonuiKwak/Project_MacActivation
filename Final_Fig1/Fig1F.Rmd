---
title: "Fig1F"
author: "Yeonui+Kwak"
date: "8/7/2020"
output: html_document
---

F1S12_7 code finalized.

1.Set a working directory
```{R}
setwd("~/Desktop/Publication_Mar/Final_Fig1/Rcode")

```

2. Setup color and load packages.
```{r}
#install.packages("raster")
library(RColorBrewer)
library(raster)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggbeeswarm)
library(gridExtra)
source("~/Desktop/Publication_Mar/Final_Supplement/Rsourcecode/scatterPlot.R")
```
```{R}
yk.col = function(n = 5, sat = 0.7, lum = 1) {
	col = c("royalblue4", "deepskyblue3", "turquoise3",
	   "grey62", "goldenrod2", "orange2", "orangered2") %>%
	col2rgb %>%
	rgb2hsv
	return(colorRampPalette(hsv(col[1,], col[2,] * sat,
				    col[3,] * lum))(n)) }
```


3. Set sub functions for a larger function.
3.1) Calulate Pearson correlation coefficient at a contigency table
Input: a contingency table, row score, and column score
output: pearson correlation value, and M2 value.

```{R}
#if(!require(coin)){install.packages("coin")}
#if(!require(rcompanion)){install.packages("rcompanion")}
library(coin);library(rcompanion)
pears.cor=function(table, rscore, cscore)
{ 
	dim=dim(table) 
	rbar=sum(margin.table(table,1)*rscore)/sum(table) 
	rdif=rscore-rbar 
	cbar=sum(margin.table(table,2)*cscore)/sum(table) 
	cdif=cscore-cbar 
	ssr=sum(margin.table(table,1)*(rdif^2)) 
	ssc=sum(margin.table(table,2)*(cdif^2)) 
	ssrc=sum(t(table*rdif)*cdif) 
	pcor=ssrc/(sqrt(ssr*ssc)) 
	pcor 
	M2=(sum(table)-1)*pcor^2
	M2
	result=c(pcor, M2)
	result
	} 

```

3.2)
```{R}
# Function to apply chisq.test() to tibble groups
diffCPS.test = function(tm, cn, rc) {
	cont.t = data.frame(time = tm, cpsNo = cn, readCount = rc) %>%
		spread(time, readCount)
	return(chisq.test(cont.t[, -1])$p.value)}

TSI.test=function(cps,tm,rc){
  cont.t=data.frame(CPS=cps,Time=tm,Readcounts=rc)%>%
    spread(CPS,Readcounts)
mat=as.matrix(cont.t[c(1:4),-1])
t=matrix(as.vector(mat),byrow=F,ncol=ncol(mat),dimnames = list("time"=rownames(mat),
                                                                "utrlen"=as.character(c(colnames(mat)))
))
#t=prop.table(t,margin=1)*100
t=as.table(round(t,0))
lt <- lbl_test(t, scores = list("utrlen"=1:ncol(t),"time"=1:nrow(t)))
  return(lt@statistic@teststatistic)
}


TSI.cor.test=function(cps,tm,rc){
  cont.t=data.frame(CPS=cps,Time=tm,Readcounts=rc)%>%
    spread(CPS,Readcounts)
mat=as.matrix(cont.t[,-1])
t=matrix(as.vector(mat),byrow=F,ncol=ncol(mat),dimnames = list("time"=rownames(mat),
                                                                "utrlen"=as.character(c(colnames(mat)))
))
#t=prop.table(t,margin=1)*100
t=as.table(round(t,0))
x=pears.cor(t,cscore=1:ncol(t),rscore=1:nrow(t))
#lt <- lbl_test(t, scores = list("utrlen"=1:ncol(t),"time"=1:nrow(t)))
  return(x[1])
}


TSI.M2.test=function(cps,tm,rc){
  cont.t=data.frame(CPS=cps,Time=tm,Readcounts=rc)%>%
    spread(CPS,Readcounts)
mat=as.matrix(cont.t[,-1])

t=matrix(as.vector(mat),byrow=F,ncol=ncol(mat),dimnames = list("time"=rownames(mat),
                                                                "utrlen"=as.character(c(colnames(mat)))
))
#t=prop.table(t,margin=1)*100
t=as.table(round(t,0))
x=pears.cor(t,cscore=1:ncol(t),rscore=1:nrow(t))
#lt <- lbl_test(t, scores = list("utrlen"=1:ncol(t),"time"=1:nrow(t)))
  return(x[2])
}
```


4. Load each temporal CPS.bed files 
1) without internal priming candiates, and then
2) with their total readcounts normalized to 1 million.

```{R}
cps.0h=read.table("cps.0h.withoutinternalpA.1million.bed", stringsAsFactors = F, header=F)
cps.1h=read.table("cps.1h.withoutinternalpA.1million.bed", stringsAsFactors = F, header=F)
cps.2h=read.table("cps.2h.withoutinternalpA.1million.bed", stringsAsFactors = F, header=F)
cps.4h=read.table("cps.4h.withoutinternalpA.1million.bed", stringsAsFactors = F, header=F)
l=list(cps.0h,cps.1h,cps.2h,cps.4h)
lapply(1:4,function(i) sum(l[[i]]$V5))
```


5.  Load CPS.all bed file gerenated from normalize temporal cps.bed files,
and already the positions with readcounts less than 5 were filtered out.
```{R}
cps.all=read.table("cps.all.full.window.internalpAremoved.gt5.bed", stringsAsFactors = F, header=F)
sum(cps.all$V5) #3,545,586 readcounts.
cat("toal cps positions",nrow(cps.all))
head(cps.all)
cps.all%>%summarise(n_distinct(V4))
```

Figure 1F.

6. Total number of poly(A) sites per gene
```{R}
#cps in all intragenic regions.
cps.ref<-read.table("cpsinallregions.bed", stringsAsFactors = F, header=F)
head(cps.ref)
cps.ref=cps.ref%>%separate(V4,c("id","chr","CPSpos"),sep=":")%>%unite("CPSid",c(chr,CPSpos),sep=":")
cps.ref%>%summarise(n_distinct(CPSid))

cps.ref=cps.ref%>%rename(hgnc=V7)
cps.ref%>%summarise(n_distinct(hgnc))
```

Number of genes with different numbers of tandem poly(A) sites.
```{R}

tmp=cps.ref%>%group_by(hgnc)%>%summarise(t=n_distinct(CPSid))%>%group_by(t)%>%summarise(n())
tmp=tmp%>%mutate(count=ifelse(t<=15,t,">15"))%>%group_by(count)%>%summarise(sum=sum(`n()`))%>%mutate(count=factor(count,levels=c(1:15,">15")))
sum(tmp$sum[tmp$count!=1])/sum(tmp$sum) #63% genes have multiple poly(A) sites.
write.table(tmp,"summaryoftallyof genes withCPScount.08.07.2020.txt",sep="\t",quote=F,row.names = F,col.names = T)
pdf("Number of genes with different numbers of poly(A) sites_08.07.2020.txt.pdf",width=4,height=3)
ggplot(tmp,aes(x=count,y=sum))+geom_bar(stat = "identity")+ylab("Number of genes")+xlab("Number of poly(A) sites per gene")+
  theme_bw()
dev.off()

```
