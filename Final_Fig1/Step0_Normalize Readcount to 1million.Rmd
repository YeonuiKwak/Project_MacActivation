---
title: "Normalize Readcount per temporal sample after internal priming removal"
author: "Yeonui+Kwak"
date: "8/7/2020"
output: html_document
---

Normalize 3p-seq positions file to total readcounts (1 million)

1. Load each temporal CPS.bed files and normalize the total readcounts to 1 million
These normalized files will be used to merge CPS peaks within 10 nucleotide windows.
```{R}
cps.0h=read.table("cps.0h.withoutinternalpA.bed", stringsAsFactors = F, header=F)
cps.1h=read.table("cps.1h.withoutinternalpA.bed", stringsAsFactors = F, header=F)
cps.2h=read.table("cps.2h.withoutinternalpA.bed", stringsAsFactors = F, header=F)
cps.4h=read.table("cps.4h.withoutinternalpA.bed", stringsAsFactors = F, header=F)
head(cps.0h)
l=list(cps.0h,cps.1h,cps.2h,cps.4h)
lapply(1:4,function(i) sum(l[[i]]$V5))
cps.all2=cps.0h%>%mutate(V5=V5/sum(cps.0h$V5)*1000000)
write.table(cps.all2,"cps.0h.withoutinternalpA.1million.bed",quote=F,col.names = F,row.names = F)
cps.all2=cps.1h%>%mutate(V5=V5/sum(cps.1h$V5)*1000000)
write.table(cps.all2,"cps.1h.withoutinternalpA.1million.bed",quote=F,col.names = F,row.names = F)
cps.all2=cps.2h%>%mutate(V5=V5/sum(cps.2h$V5)*1000000)
write.table(cps.all2,"cps.2h.withoutinternalpA.1million.bed",quote=F,col.names = F,row.names = F)
cps.all2=cps.4h%>%mutate(V5=V5/sum(cps.4h$V5)*1000000)
write.table(cps.all2,"cps.4h.withoutinternalpA.1million.bed",quote=F,col.names = F,row.names = F)
```


